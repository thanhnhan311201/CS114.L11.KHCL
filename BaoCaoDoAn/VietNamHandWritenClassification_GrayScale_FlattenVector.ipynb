{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MathForCS.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DCyqCZbAiLPA"
      ],
      "authorship_tag": "ABX9TyPBzkchjXp/jkitlQHMl+Cw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhnhan311201/CS114.L11.KHCL/blob/master/VietNamHandWritenClassification_GrayScale_FlattenVector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aEEBKsHawj0",
        "outputId": "faa5ddaa-f5e7-4dad-b426-8dbe7094166d"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-bifFsRbTtg"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwmrAKAZndqG"
      },
      "source": [
        "list_class = sorted(os.listdir('/content/drive/MyDrive/Dataset/Dataset'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z33U_bAbeyn"
      },
      "source": [
        "def read_data(pathX, pathY):\n",
        "    data_X = pd.read_csv(pathX, header=None)\n",
        "    label_Y = pd.read_csv(pathY, header=None)\n",
        "    return np.array(data_X), np.array(label_Y).ravel()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAPOmw25b_-2"
      },
      "source": [
        "train_path = '/content/drive/MyDrive/BackUpData/TrimImage/X_train.csv'\n",
        "label_train_path = '/content/drive/MyDrive/BackUpData/Y_train.csv'\n",
        "\n",
        "test_path = '/content/drive/MyDrive/BackUpData/TrimImage/X_test.csv'\n",
        "val_path = '/content/drive/MyDrive/BackUpData/TrimImage/X_val.csv'\n",
        "\n",
        "label_test_path = '/content/drive/MyDrive/BackUpData/Y_test.csv'\n",
        "label_val_path = '/content/drive/MyDrive/BackUpData/Y_vali.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-YoNeS6cTet"
      },
      "source": [
        "X_train, Y_train = read_data(train_path, label_train_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY4P00gFcvWS"
      },
      "source": [
        "X_test, Y_test = read_data(test_path, label_test_path)\n",
        "X_val, Y_val = read_data(val_path, label_val_path)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pKVA1yWc_KF"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVLJWYOPh6-z"
      },
      "source": [
        "Scaler = MinMaxScaler()\n",
        "Scaler.fit(X_train)\n",
        "\n",
        "x_train = Scaler.transform(X_train)\n",
        "x_test = Scaler.transform(X_test)\n",
        "x_val = Scaler.transform(X_val)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oUswKtEjJzN"
      },
      "source": [
        "y_train = Y_train\n",
        "y_test = Y_test\n",
        "y_val = Y_val"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTG36yLI6dur"
      },
      "source": [
        "#Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsJQwWFLdS5V"
      },
      "source": [
        "Lgr1= LogisticRegression(C=0.1, solver = 'liblinear', max_iter = 1000)\n",
        "Lgr1.fit(x_train, y_train)\n",
        "y_pred_val = Lgr1.predict(x_val)\n",
        "y_pred_test = Lgr1.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrWoaFkD63yf",
        "outputId": "83ad6792-0036-4965-b016-f934731f4d32"
      },
      "source": [
        "print(classification_report(y_val, Lgr1.predict(x_val), target_names=list_class))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           a       0.73      0.61      0.67        36\n",
            "          à       0.17      0.08      0.11        36\n",
            "          á       0.22      0.17      0.19        36\n",
            "          â       0.17      0.11      0.14        35\n",
            "         ầ       0.04      0.03      0.03        35\n",
            "         ấ       0.15      0.22      0.18        36\n",
            "         ẫ       0.24      0.39      0.29        36\n",
            "         ẩ       0.17      0.08      0.11        36\n",
            "          ã       0.09      0.08      0.09        36\n",
            "          ă       0.29      0.17      0.21        36\n",
            "         ằ       0.20      0.19      0.20        36\n",
            "         ắ       0.22      0.19      0.21        36\n",
            "         ẵ       0.23      0.31      0.27        36\n",
            "         ẳ       0.14      0.17      0.15        36\n",
            "          ả       0.19      0.17      0.18        36\n",
            "          ạ       0.35      0.31      0.33        36\n",
            "         ậ       0.35      0.54      0.43        35\n",
            "         ặ       0.16      0.31      0.21        36\n",
            "           b       0.50      0.31      0.39        35\n",
            "           c       0.68      0.38      0.49        34\n",
            "           d       0.35      0.26      0.30        34\n",
            "           e       0.47      0.26      0.34        34\n",
            "          è       0.42      0.36      0.38        28\n",
            "          é       0.38      0.36      0.37        28\n",
            "          ê       0.50      0.25      0.33        28\n",
            "         ề       0.31      0.14      0.20        28\n",
            "         ế       0.28      0.29      0.28        28\n",
            "         ễ       0.25      0.04      0.06        28\n",
            "         ể       0.14      0.11      0.12        28\n",
            "          ẽ       0.16      0.11      0.13        28\n",
            "          ẻ       0.46      0.43      0.44        28\n",
            "          ẹ       0.29      0.29      0.29        28\n",
            "         ệ       0.22      0.07      0.11        28\n",
            "           g       0.18      0.07      0.10        28\n",
            "           h       0.47      0.29      0.36        28\n",
            "           i       0.15      0.11      0.12        28\n",
            "          ì       0.25      0.21      0.23        28\n",
            "          í       0.07      0.04      0.05        28\n",
            "          ĩ       0.55      0.39      0.46        28\n",
            "          ỉ       0.32      0.39      0.35        28\n",
            "          ị       0.26      0.21      0.24        28\n",
            "           k       0.10      0.25      0.15        40\n",
            "           l       0.15      0.30      0.20        40\n",
            "           m       0.35      0.29      0.31        28\n",
            "           n       0.29      0.18      0.22        28\n",
            "           o       0.71      0.56      0.63        36\n",
            "          ò       0.40      0.22      0.29        36\n",
            "          ó       0.40      0.28      0.33        36\n",
            "          ô       0.22      0.14      0.17        36\n",
            "         ồ       0.07      0.03      0.04        36\n",
            "         ố       0.20      0.31      0.24        36\n",
            "         ỗ       0.06      0.06      0.06        36\n",
            "         ổ       0.11      0.19      0.14        36\n",
            "          õ       0.12      0.11      0.12        36\n",
            "          ỏ       0.27      0.19      0.23        36\n",
            "          ơ       0.14      0.14      0.14        36\n",
            "         ờ       0.06      0.03      0.04        36\n",
            "         ớ       0.06      0.03      0.04        36\n",
            "         ỡ       0.31      0.31      0.31        36\n",
            "         ở       0.30      0.19      0.24        36\n",
            "         ợ       0.39      0.50      0.44        36\n",
            "          ọ       0.32      0.22      0.26        36\n",
            "         ộ       0.17      0.33      0.22        36\n",
            "           p       0.56      0.42      0.48        36\n",
            "           q       0.43      0.26      0.33        34\n",
            "           r       0.30      0.26      0.28        35\n",
            "           s       0.39      0.21      0.27        34\n",
            "           t       0.26      0.41      0.32        34\n",
            "           u       0.71      0.73      0.72        30\n",
            "          ù       0.36      0.43      0.39        28\n",
            "          ú       0.26      0.32      0.29        28\n",
            "          ũ       0.53      0.32      0.40        28\n",
            "          ủ       0.30      0.25      0.27        28\n",
            "          ư       0.48      0.57      0.52        28\n",
            "         ừ       0.17      0.21      0.19        28\n",
            "         ứ       0.33      0.18      0.23        28\n",
            "         ữ       0.13      0.11      0.12        28\n",
            "         ử       0.25      0.21      0.23        28\n",
            "         ự       0.38      0.11      0.17        28\n",
            "          ụ       0.78      0.52      0.62        27\n",
            "           v       0.33      0.14      0.20        28\n",
            "           x       0.08      0.28      0.13        40\n",
            "           y       0.26      0.33      0.29        30\n",
            "          ỳ       0.09      0.20      0.12        51\n",
            "          ý       0.12      0.17      0.14        53\n",
            "          ỹ       0.54      0.67      0.60        52\n",
            "          ỷ       0.16      0.35      0.22        52\n",
            "          ỵ       0.77      0.67      0.72        36\n",
            "           đ       0.30      0.41      0.35        34\n",
            "\n",
            "    accuracy                           0.26      2984\n",
            "   macro avg       0.30      0.26      0.26      2984\n",
            "weighted avg       0.29      0.26      0.26      2984\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x_WdkdJ8e-Y",
        "outputId": "517e6a21-70d6-4127-aeb9-a22d93662b73"
      },
      "source": [
        "print(classification_report(y_pred_test, y_test, target_names=list_class))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           a       0.10      0.75      0.18         4\n",
            "          à       0.00      0.00      0.00         4\n",
            "          á       0.00      0.00      0.00         7\n",
            "          â       0.00      0.00      0.00         2\n",
            "         ầ       0.07      0.33      0.11         6\n",
            "         ấ       0.07      0.14      0.09        14\n",
            "         ẫ       0.27      0.73      0.39        11\n",
            "         ẩ       0.07      0.07      0.07        29\n",
            "          ã       0.00      0.00      0.00         7\n",
            "          ă       0.00      0.00      0.00         1\n",
            "         ằ       0.03      0.05      0.04        20\n",
            "         ắ       0.00      0.00      0.00         9\n",
            "         ẵ       0.07      0.14      0.09        14\n",
            "         ẳ       0.10      0.09      0.09        35\n",
            "          ả       0.03      0.33      0.06         3\n",
            "          ạ       0.03      0.50      0.06         2\n",
            "         ậ       0.33      0.62      0.43        16\n",
            "         ặ       0.00      0.00      0.00        13\n",
            "           b       0.27      0.67      0.38        12\n",
            "           c       0.30      1.00      0.46         9\n",
            "           d       0.27      0.35      0.30        23\n",
            "           e       0.27      0.89      0.41         9\n",
            "          è       0.00      0.00      0.00         0\n",
            "          é       0.03      0.50      0.06         2\n",
            "          ê       0.00      0.00      0.00         3\n",
            "         ề       0.00      0.00      0.00         4\n",
            "         ế       0.00      0.00      0.00         8\n",
            "         ễ       0.00      0.00      0.00        16\n",
            "         ể       0.00      0.00      0.00         5\n",
            "          ẽ       0.00      0.00      0.00         1\n",
            "          ẻ       0.00      0.00      0.00         8\n",
            "          ẹ       0.00      0.00      0.00         2\n",
            "         ệ       0.03      1.00      0.06         1\n",
            "           g       0.00      0.00      0.00         8\n",
            "           h       0.00      0.00      0.00        11\n",
            "           i       0.00      0.00      0.00        28\n",
            "          ì       0.37      0.08      0.13       145\n",
            "          í       0.30      0.07      0.11       131\n",
            "          ĩ       0.33      0.45      0.38        22\n",
            "          ỉ       0.07      0.40      0.11         5\n",
            "          ị       0.00      0.00      0.00         8\n",
            "           k       0.38      0.05      0.08       502\n",
            "           l       0.38      0.05      0.08       411\n",
            "           m       0.03      0.14      0.05         7\n",
            "           n       0.00      0.00      0.00         3\n",
            "           o       0.23      0.88      0.37         8\n",
            "          ò       0.00      0.00      0.00         3\n",
            "          ó       0.00      0.00      0.00         6\n",
            "          ô       0.00      0.00      0.00         0\n",
            "         ồ       0.03      0.33      0.06         3\n",
            "         ố       0.03      0.12      0.05         8\n",
            "         ỗ       0.10      0.07      0.08        46\n",
            "         ổ       0.23      0.09      0.13        78\n",
            "          õ       0.07      0.13      0.09        15\n",
            "          ỏ       0.00      0.00      0.00         4\n",
            "          ơ       0.00      0.00      0.00        25\n",
            "         ờ       0.00      0.00      0.00        16\n",
            "         ớ       0.20      0.21      0.20        29\n",
            "         ỡ       0.30      0.64      0.41        14\n",
            "         ở       0.20      0.43      0.27        14\n",
            "         ợ       0.30      0.90      0.45        10\n",
            "          ọ       0.03      0.08      0.05        12\n",
            "         ộ       0.07      0.13      0.09        15\n",
            "           p       0.23      0.88      0.37         8\n",
            "           q       0.30      0.50      0.37        18\n",
            "           r       0.33      0.09      0.14       112\n",
            "           s       0.23      0.54      0.33        13\n",
            "           t       0.13      0.44      0.21         9\n",
            "           u       0.00      0.00      0.00         1\n",
            "          ù       0.00      0.00      0.00         2\n",
            "          ú       0.03      0.25      0.06         4\n",
            "          ũ       0.00      0.00      0.00         6\n",
            "          ủ       0.00      0.00      0.00         3\n",
            "          ư       0.00      0.00      0.00         2\n",
            "         ừ       0.07      0.04      0.05        52\n",
            "         ứ       0.00      0.00      0.00         8\n",
            "         ữ       0.07      0.06      0.06        33\n",
            "         ử       0.23      0.08      0.12        88\n",
            "         ự       0.00      0.00      0.00         2\n",
            "          ụ       0.00      0.00      0.00         0\n",
            "           v       0.03      0.08      0.05        13\n",
            "           x       0.32      0.07      0.11       289\n",
            "           y       0.03      0.10      0.04        10\n",
            "          ỳ       0.20      0.05      0.08       127\n",
            "          ý       0.03      0.05      0.04        21\n",
            "          ỹ       0.00      0.00      0.00         2\n",
            "          ỷ       0.07      0.05      0.06        37\n",
            "          ỵ       0.00      0.00      0.00         0\n",
            "           đ       0.27      0.73      0.39        11\n",
            "\n",
            "    accuracy                           0.10      2758\n",
            "   macro avg       0.10      0.20      0.10      2758\n",
            "weighted avg       0.26      0.10      0.11      2758\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP8d9B9h6bON"
      },
      "source": [
        "#NoneLinear SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y-rbbJu6FsI"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDPuW0-o6sAc",
        "outputId": "44f9ba07-c025-4e80-e07f-f98e73282331"
      },
      "source": [
        "SVC_model = SVC()\n",
        "SVC_model.fit(x_train, y_train)\n",
        "print(accuracy_score(y_val, SVC_model.predict(x_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2737935656836461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck8VPjWv7MLd",
        "outputId": "c43e9056-0012-421a-f058-7fc670d58dce"
      },
      "source": [
        "print(accuracy_score(y_test, SVC_model.predict(x_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0725163161711385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjIkJ-vC8hzt",
        "outputId": "2d8a4057-dba1-4eab-eaca-bf2c54aa51d2"
      },
      "source": [
        "SVC_model1 = SVC(C=5)\n",
        "SVC_model1.fit(x_train, y_train)\n",
        "print(accuracy_score(y_val, SVC_model1.predict(x_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3726541554959786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OAW_j6q9u69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72946430-c2dc-4fec-fb11-bcaf8549a1bc"
      },
      "source": [
        "SVC_model2 = SVC(C=6)\n",
        "SVC_model2.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=6, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTzyK79g-1v4",
        "outputId": "5401a41a-6798-483e-c203-c8cc20604491"
      },
      "source": [
        "print(accuracy_score(y_val, SVC_model2.predict(x_val)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.38337801608579086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIFOsDEHEogy",
        "outputId": "bb53aec7-d28b-4e50-e55c-7a244ea4ee87"
      },
      "source": [
        "SVC_model3 = SVC(C=8)\n",
        "SVC_model3.fit(x_train, y_train)\n",
        "print(accuracy_score(y_val, SVC_model3.predict(x_val)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3867292225201072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VTPumFmiSbL",
        "outputId": "3a0ed3d7-3639-4dc9-c993-bb7b0cc21e67"
      },
      "source": [
        "print(classification_report(y_val, SVC_model3.predict(x_val)))\n",
        "print(classification_report(y_test, SVC_model3.predict(x_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.67      0.68        36\n",
            "           1       0.37      0.36      0.37        36\n",
            "           2       0.45      0.36      0.40        36\n",
            "           3       0.25      0.20      0.22        35\n",
            "           4       0.11      0.11      0.11        35\n",
            "           5       0.22      0.36      0.28        36\n",
            "           6       0.30      0.31      0.30        36\n",
            "           7       0.23      0.19      0.21        36\n",
            "           8       0.15      0.14      0.14        36\n",
            "           9       0.30      0.36      0.33        36\n",
            "          10       0.19      0.25      0.21        36\n",
            "          11       0.27      0.36      0.31        36\n",
            "          12       0.26      0.31      0.28        36\n",
            "          13       0.23      0.25      0.24        36\n",
            "          14       0.42      0.44      0.43        36\n",
            "          15       0.41      0.50      0.45        36\n",
            "          16       0.56      0.51      0.54        35\n",
            "          17       0.17      0.36      0.23        36\n",
            "          18       0.64      0.40      0.49        35\n",
            "          19       0.57      0.47      0.52        34\n",
            "          20       0.44      0.35      0.39        34\n",
            "          21       0.72      0.38      0.50        34\n",
            "          22       0.52      0.54      0.53        28\n",
            "          23       0.45      0.61      0.52        28\n",
            "          24       0.54      0.25      0.34        28\n",
            "          25       0.58      0.39      0.47        28\n",
            "          26       0.40      0.43      0.41        28\n",
            "          27       0.50      0.18      0.26        28\n",
            "          28       0.29      0.29      0.29        28\n",
            "          29       0.39      0.32      0.35        28\n",
            "          30       0.63      0.61      0.62        28\n",
            "          31       0.34      0.46      0.39        28\n",
            "          32       0.38      0.21      0.27        28\n",
            "          33       0.32      0.32      0.32        28\n",
            "          34       0.60      0.32      0.42        28\n",
            "          35       0.16      0.21      0.18        28\n",
            "          36       0.37      0.39      0.38        28\n",
            "          37       0.27      0.32      0.30        28\n",
            "          38       0.90      0.68      0.78        28\n",
            "          39       0.33      0.39      0.36        28\n",
            "          40       0.56      0.18      0.27        28\n",
            "          41       0.23      0.50      0.31        40\n",
            "          42       0.37      0.55      0.44        40\n",
            "          43       0.50      0.54      0.52        28\n",
            "          44       0.41      0.32      0.36        28\n",
            "          45       0.83      0.53      0.64        36\n",
            "          46       0.44      0.39      0.41        36\n",
            "          47       0.33      0.44      0.38        36\n",
            "          48       0.35      0.39      0.37        36\n",
            "          49       0.36      0.28      0.31        36\n",
            "          50       0.38      0.42      0.40        36\n",
            "          51       0.29      0.17      0.21        36\n",
            "          52       0.22      0.28      0.25        36\n",
            "          53       0.32      0.17      0.22        36\n",
            "          54       0.38      0.42      0.39        36\n",
            "          55       0.23      0.39      0.29        36\n",
            "          56       0.16      0.11      0.13        36\n",
            "          57       0.33      0.17      0.22        36\n",
            "          58       0.43      0.42      0.42        36\n",
            "          59       0.39      0.19      0.26        36\n",
            "          60       0.57      0.47      0.52        36\n",
            "          61       0.30      0.42      0.35        36\n",
            "          62       0.32      0.33      0.32        36\n",
            "          63       0.53      0.58      0.55        36\n",
            "          64       0.58      0.56      0.57        34\n",
            "          65       0.43      0.34      0.38        35\n",
            "          66       0.69      0.26      0.38        34\n",
            "          67       0.47      0.56      0.51        34\n",
            "          68       0.77      0.80      0.79        30\n",
            "          69       0.54      0.46      0.50        28\n",
            "          70       0.47      0.54      0.50        28\n",
            "          71       0.62      0.36      0.45        28\n",
            "          72       0.33      0.18      0.23        28\n",
            "          73       0.53      0.61      0.57        28\n",
            "          74       0.28      0.32      0.30        28\n",
            "          75       0.36      0.29      0.32        28\n",
            "          76       0.36      0.32      0.34        28\n",
            "          77       0.26      0.32      0.29        28\n",
            "          78       0.62      0.29      0.39        28\n",
            "          79       0.93      0.52      0.67        27\n",
            "          80       0.20      0.21      0.21        28\n",
            "          81       0.14      0.35      0.20        40\n",
            "          82       0.30      0.27      0.28        30\n",
            "          83       0.53      0.51      0.52        51\n",
            "          84       0.52      0.51      0.51        53\n",
            "          85       0.70      0.71      0.70        52\n",
            "          86       0.46      0.44      0.45        52\n",
            "          87       0.77      0.67      0.72        36\n",
            "          88       0.59      0.47      0.52        34\n",
            "\n",
            "    accuracy                           0.39      2984\n",
            "   macro avg       0.42      0.38      0.39      2984\n",
            "weighted avg       0.42      0.39      0.39      2984\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.13      0.23        30\n",
            "           1       0.00      0.00      0.00        30\n",
            "           2       0.00      0.00      0.00        30\n",
            "           3       0.00      0.00      0.00        30\n",
            "           4       0.00      0.00      0.00        30\n",
            "           5       0.43      0.10      0.16        30\n",
            "           6       0.02      0.80      0.04        30\n",
            "           7       0.14      0.03      0.05        30\n",
            "           8       0.33      0.03      0.06        30\n",
            "           9       0.40      0.13      0.20        30\n",
            "          10       0.12      0.03      0.05        30\n",
            "          11       0.14      0.03      0.05        30\n",
            "          12       0.03      0.40      0.06        30\n",
            "          13       0.62      0.17      0.26        30\n",
            "          14       0.43      0.20      0.27        30\n",
            "          15       0.33      0.20      0.25        30\n",
            "          16       0.83      0.33      0.48        30\n",
            "          17       0.00      0.00      0.00        30\n",
            "          18       1.00      0.30      0.46        30\n",
            "          19       0.60      0.30      0.40        30\n",
            "          20       0.43      0.30      0.35        30\n",
            "          21       0.77      0.33      0.47        30\n",
            "          22       0.00      0.00      0.00        30\n",
            "          23       0.33      0.03      0.06        30\n",
            "          24       0.00      0.00      0.00        30\n",
            "          25       0.00      0.00      0.00        30\n",
            "          26       0.00      0.00      0.00        30\n",
            "          27       0.00      0.00      0.00        30\n",
            "          28       0.00      0.00      0.00        30\n",
            "          29       0.00      0.00      0.00        30\n",
            "          30       0.00      0.00      0.00        30\n",
            "          31       0.00      0.00      0.00        30\n",
            "          32       0.00      0.00      0.00        30\n",
            "          33       0.13      0.23      0.17        30\n",
            "          34       0.00      0.00      0.00        30\n",
            "          35       0.05      0.23      0.08        40\n",
            "          36       0.57      0.13      0.22        30\n",
            "          37       0.11      0.10      0.10        30\n",
            "          38       1.00      0.03      0.06        30\n",
            "          39       0.00      0.00      0.00        30\n",
            "          40       0.00      0.00      0.00        30\n",
            "          41       0.19      0.07      0.10        60\n",
            "          42       0.83      0.10      0.18        50\n",
            "          43       0.00      0.00      0.00        30\n",
            "          44       0.00      0.00      0.00        29\n",
            "          45       0.50      0.23      0.32        30\n",
            "          46       0.00      0.00      0.00        30\n",
            "          47       0.04      0.10      0.05        30\n",
            "          48       1.00      0.10      0.18        30\n",
            "          49       0.60      0.10      0.17        30\n",
            "          50       0.20      0.07      0.10        30\n",
            "          51       0.00      0.00      0.00        30\n",
            "          52       0.00      0.00      0.00        30\n",
            "          53       0.10      0.03      0.05        30\n",
            "          54       0.17      0.17      0.17        30\n",
            "          55       0.00      0.00      0.00        30\n",
            "          56       1.00      0.03      0.06        30\n",
            "          57       0.00      0.00      0.00        30\n",
            "          58       0.69      0.30      0.42        30\n",
            "          59       0.75      0.10      0.18        30\n",
            "          60       0.90      0.30      0.45        30\n",
            "          61       0.06      0.07      0.06        30\n",
            "          62       0.00      0.00      0.00        30\n",
            "          63       0.64      0.30      0.41        30\n",
            "          64       1.00      0.30      0.46        30\n",
            "          65       0.82      0.30      0.44        30\n",
            "          66       0.83      0.33      0.48        30\n",
            "          67       0.78      0.23      0.36        30\n",
            "          68       0.00      0.00      0.00        30\n",
            "          69       0.00      0.00      0.00        30\n",
            "          70       0.33      0.03      0.06        30\n",
            "          71       0.00      0.00      0.00        30\n",
            "          72       0.00      0.00      0.00        30\n",
            "          73       0.00      0.00      0.00        30\n",
            "          74       0.00      0.00      0.00        30\n",
            "          75       0.00      0.00      0.00        30\n",
            "          76       0.00      0.00      0.00        30\n",
            "          77       0.09      0.10      0.09        30\n",
            "          78       0.00      0.00      0.00        30\n",
            "          79       0.00      0.00      0.00        30\n",
            "          80       0.00      0.00      0.00        30\n",
            "          81       0.06      0.03      0.04        60\n",
            "          82       0.29      0.05      0.09        39\n",
            "          83       0.00      0.00      0.00        30\n",
            "          84       0.00      0.00      0.00        30\n",
            "          85       0.00      0.00      0.00        30\n",
            "          86       0.50      0.10      0.17        30\n",
            "          87       0.04      0.55      0.08        20\n",
            "          88       0.17      0.50      0.25        30\n",
            "\n",
            "    accuracy                           0.10      2758\n",
            "   macro avg       0.25      0.10      0.11      2758\n",
            "weighted avg       0.25      0.10      0.11      2758\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCyqCZbAiLPA"
      },
      "source": [
        "#Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoWZnweoZQHh"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkDP5Yz1i4jQ",
        "outputId": "290e0a0e-5832-4b76-fcda-7731caada733"
      },
      "source": [
        "LinearSVC_model1 = LinearSVC()\n",
        "LinearSVC_model1.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNq5miKSjFje",
        "outputId": "52cf3768-9e90-4288-ed4a-c7af0f8b182d"
      },
      "source": [
        "print(accuracy_score(y_val, LinearSVC_model1.predict(x_val)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.21514745308310992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_-ptcuIlfhp",
        "outputId": "94818b3e-4d32-4f26-9405-be1447eca61f"
      },
      "source": [
        "LinearSVC_model2 = LinearSVC(C=5, max_iter = 3000, multi_class = 'crammer_singer')\n",
        "LinearSVC_model2.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=3000,\n",
              "          multi_class='crammer_singer', penalty='l2', random_state=None,\n",
              "          tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEIBgIXFtCc4",
        "outputId": "799d5886-954c-4ccf-df1e-f0b5d6c09494"
      },
      "source": [
        "print(classification_report(y_val, LinearSVC_model2.predict(x_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.47      0.49        36\n",
            "           1       0.12      0.11      0.12        36\n",
            "           2       0.26      0.28      0.27        36\n",
            "           3       0.12      0.09      0.10        35\n",
            "           4       0.11      0.06      0.08        35\n",
            "           5       0.17      0.17      0.17        36\n",
            "           6       0.31      0.39      0.35        36\n",
            "           7       0.12      0.08      0.10        36\n",
            "           8       0.13      0.14      0.13        36\n",
            "           9       0.20      0.17      0.18        36\n",
            "          10       0.24      0.17      0.20        36\n",
            "          11       0.24      0.25      0.24        36\n",
            "          12       0.23      0.25      0.24        36\n",
            "          13       0.30      0.17      0.21        36\n",
            "          14       0.30      0.31      0.30        36\n",
            "          15       0.29      0.28      0.29        36\n",
            "          16       0.27      0.37      0.31        35\n",
            "          17       0.14      0.11      0.12        36\n",
            "          18       0.36      0.29      0.32        35\n",
            "          19       0.32      0.35      0.34        34\n",
            "          20       0.13      0.12      0.12        34\n",
            "          21       0.33      0.29      0.31        34\n",
            "          22       0.23      0.21      0.22        28\n",
            "          23       0.24      0.43      0.31        28\n",
            "          24       0.18      0.18      0.18        28\n",
            "          25       0.29      0.21      0.24        28\n",
            "          26       0.18      0.25      0.21        28\n",
            "          27       0.06      0.04      0.04        28\n",
            "          28       0.05      0.07      0.06        28\n",
            "          29       0.22      0.25      0.23        28\n",
            "          30       0.22      0.29      0.25        28\n",
            "          31       0.15      0.21      0.18        28\n",
            "          32       0.13      0.14      0.14        28\n",
            "          33       0.22      0.25      0.23        28\n",
            "          34       0.31      0.29      0.30        28\n",
            "          35       0.12      0.11      0.11        28\n",
            "          36       0.21      0.25      0.23        28\n",
            "          37       0.12      0.14      0.13        28\n",
            "          38       0.27      0.29      0.28        28\n",
            "          39       0.21      0.32      0.25        28\n",
            "          40       0.12      0.14      0.13        28\n",
            "          41       0.22      0.10      0.14        40\n",
            "          42       0.38      0.23      0.28        40\n",
            "          43       0.30      0.39      0.34        28\n",
            "          44       0.18      0.32      0.23        28\n",
            "          45       0.47      0.42      0.44        36\n",
            "          46       0.29      0.28      0.29        36\n",
            "          47       0.18      0.17      0.17        36\n",
            "          48       0.25      0.22      0.24        36\n",
            "          49       0.22      0.11      0.15        36\n",
            "          50       0.27      0.17      0.21        36\n",
            "          51       0.06      0.03      0.04        36\n",
            "          52       0.18      0.17      0.17        36\n",
            "          53       0.14      0.11      0.12        36\n",
            "          54       0.19      0.17      0.18        36\n",
            "          55       0.17      0.11      0.13        36\n",
            "          56       0.09      0.08      0.09        36\n",
            "          57       0.00      0.00      0.00        36\n",
            "          58       0.28      0.31      0.29        36\n",
            "          59       0.32      0.17      0.22        36\n",
            "          60       0.38      0.36      0.37        36\n",
            "          61       0.17      0.08      0.11        36\n",
            "          62       0.17      0.14      0.15        36\n",
            "          63       0.38      0.50      0.43        36\n",
            "          64       0.32      0.35      0.34        34\n",
            "          65       0.33      0.20      0.25        35\n",
            "          66       0.21      0.21      0.21        34\n",
            "          67       0.28      0.41      0.33        34\n",
            "          68       0.44      0.60      0.51        30\n",
            "          69       0.27      0.43      0.33        28\n",
            "          70       0.23      0.32      0.26        28\n",
            "          71       0.20      0.25      0.22        28\n",
            "          72       0.12      0.18      0.14        28\n",
            "          73       0.38      0.54      0.44        28\n",
            "          74       0.17      0.25      0.20        28\n",
            "          75       0.10      0.07      0.08        28\n",
            "          76       0.15      0.14      0.15        28\n",
            "          77       0.22      0.32      0.26        28\n",
            "          78       0.20      0.14      0.17        28\n",
            "          79       0.34      0.44      0.39        27\n",
            "          80       0.13      0.14      0.14        28\n",
            "          81       0.09      0.07      0.08        40\n",
            "          82       0.06      0.07      0.06        30\n",
            "          83       0.21      0.20      0.20        51\n",
            "          84       0.26      0.26      0.26        53\n",
            "          85       0.38      0.54      0.44        52\n",
            "          86       0.33      0.27      0.29        52\n",
            "          87       0.50      0.56      0.53        36\n",
            "          88       0.30      0.38      0.34        34\n",
            "\n",
            "    accuracy                           0.24      2984\n",
            "   macro avg       0.23      0.24      0.23      2984\n",
            "weighted avg       0.23      0.24      0.23      2984\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWOK3vm29vdh",
        "outputId": "45e760fb-6ec1-4ab2-9d37-c939959e363c"
      },
      "source": [
        "print(classification_report(y_test, LinearSVC_model2.predict(x_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.10      0.16        30\n",
            "           1       0.00      0.00      0.00        30\n",
            "           2       0.04      0.03      0.04        30\n",
            "           3       0.00      0.00      0.00        30\n",
            "           4       0.33      0.03      0.06        30\n",
            "           5       0.20      0.03      0.06        30\n",
            "           6       0.70      0.23      0.35        30\n",
            "           7       0.04      0.03      0.04        30\n",
            "           8       0.00      0.00      0.00        30\n",
            "           9       0.20      0.07      0.10        30\n",
            "          10       0.25      0.03      0.06        30\n",
            "          11       0.00      0.00      0.00        30\n",
            "          12       0.04      0.07      0.05        30\n",
            "          13       0.00      0.00      0.00        30\n",
            "          14       0.15      0.10      0.12        30\n",
            "          15       0.43      0.10      0.16        30\n",
            "          16       0.48      0.33      0.39        30\n",
            "          17       0.00      0.00      0.00        30\n",
            "          18       0.62      0.27      0.37        30\n",
            "          19       0.42      0.33      0.37        30\n",
            "          20       0.27      0.23      0.25        30\n",
            "          21       0.69      0.30      0.42        30\n",
            "          22       0.25      0.03      0.06        30\n",
            "          23       0.17      0.03      0.06        30\n",
            "          24       0.00      0.00      0.00        30\n",
            "          25       0.00      0.00      0.00        30\n",
            "          26       0.06      0.03      0.04        30\n",
            "          27       0.00      0.00      0.00        30\n",
            "          28       0.04      0.03      0.04        30\n",
            "          29       0.00      0.00      0.00        30\n",
            "          30       0.05      0.03      0.04        30\n",
            "          31       0.00      0.00      0.00        30\n",
            "          32       0.00      0.00      0.00        30\n",
            "          33       0.00      0.00      0.00        30\n",
            "          34       0.00      0.00      0.00        30\n",
            "          35       0.00      0.00      0.00        40\n",
            "          36       0.17      0.07      0.10        30\n",
            "          37       0.11      0.10      0.10        30\n",
            "          38       0.23      0.10      0.14        30\n",
            "          39       0.00      0.00      0.00        30\n",
            "          40       0.17      0.03      0.06        30\n",
            "          41       0.00      0.00      0.00        60\n",
            "          42       0.03      0.60      0.05        50\n",
            "          43       0.50      0.20      0.29        30\n",
            "          44       0.00      0.00      0.00        29\n",
            "          45       0.43      0.20      0.27        30\n",
            "          46       0.16      0.10      0.12        30\n",
            "          47       0.29      0.07      0.11        30\n",
            "          48       0.00      0.00      0.00        30\n",
            "          49       0.00      0.00      0.00        30\n",
            "          50       0.09      0.03      0.05        30\n",
            "          51       0.25      0.03      0.06        30\n",
            "          52       0.03      0.30      0.06        30\n",
            "          53       0.00      0.00      0.00        30\n",
            "          54       0.22      0.27      0.24        30\n",
            "          55       0.00      0.00      0.00        30\n",
            "          56       0.00      0.00      0.00        30\n",
            "          57       0.00      0.00      0.00        30\n",
            "          58       0.82      0.30      0.44        30\n",
            "          59       0.50      0.10      0.17        30\n",
            "          60       0.47      0.23      0.31        30\n",
            "          61       0.00      0.00      0.00        30\n",
            "          62       0.00      0.00      0.00        30\n",
            "          63       0.50      0.30      0.37        30\n",
            "          64       1.00      0.27      0.42        30\n",
            "          65       0.57      0.27      0.36        30\n",
            "          66       0.47      0.23      0.31        30\n",
            "          67       0.62      0.27      0.37        30\n",
            "          68       1.00      0.03      0.06        30\n",
            "          69       0.11      0.07      0.08        30\n",
            "          70       0.03      0.03      0.03        30\n",
            "          71       0.00      0.00      0.00        30\n",
            "          72       0.09      0.03      0.05        30\n",
            "          73       0.00      0.00      0.00        30\n",
            "          74       0.00      0.00      0.00        30\n",
            "          75       0.00      0.00      0.00        30\n",
            "          76       0.00      0.00      0.00        30\n",
            "          77       0.12      0.07      0.09        30\n",
            "          78       0.00      0.00      0.00        30\n",
            "          79       0.00      0.00      0.00        30\n",
            "          80       0.00      0.00      0.00        30\n",
            "          81       0.00      0.00      0.00        60\n",
            "          82       0.00      0.00      0.00        39\n",
            "          83       0.04      0.40      0.08        30\n",
            "          84       0.11      0.03      0.05        30\n",
            "          85       0.00      0.00      0.00        30\n",
            "          86       0.00      0.00      0.00        30\n",
            "          87       0.00      0.00      0.00        20\n",
            "          88       0.82      0.30      0.44        30\n",
            "\n",
            "    accuracy                           0.09      2758\n",
            "   macro avg       0.18      0.08      0.10      2758\n",
            "weighted avg       0.17      0.09      0.09      2758\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz0SrjMf93XY"
      },
      "source": [
        "#Naive bayes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riRWMsUJ_MwM"
      },
      "source": [
        "from sklearn.naive_bayes import ComplementNB, GaussianNB, MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eq6sfAEAUxZ",
        "outputId": "12f869e3-2cbf-4ebe-fc44-73fbd62d6773"
      },
      "source": [
        "GNB = GaussianNB()\n",
        "GNB.fit(x_train, y_train)\n",
        "print(accuracy_score(y_val, GNB.predict(x_val)))\n",
        "print(accuracy_score(y_test, GNB.predict(x_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2168230563002681\n",
            "0.048585931834662796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJHSVnoznZfy",
        "outputId": "4343833e-f4bd-4336-cc74-d0b850c22b43"
      },
      "source": [
        "print(classification_report(y_val, GNB.predict(x_val)))\n",
        "print(classification_report(y_test, GNB.predict(x_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.72      0.63        36\n",
            "           1       0.19      0.08      0.12        36\n",
            "           2       0.18      0.08      0.11        36\n",
            "           3       0.00      0.00      0.00        35\n",
            "           4       0.00      0.00      0.00        35\n",
            "           5       0.08      0.42      0.13        36\n",
            "           6       0.58      0.19      0.29        36\n",
            "           7       0.00      0.00      0.00        36\n",
            "           8       0.57      0.11      0.19        36\n",
            "           9       0.27      0.25      0.26        36\n",
            "          10       0.16      0.19      0.18        36\n",
            "          11       0.00      0.00      0.00        36\n",
            "          12       0.60      0.08      0.15        36\n",
            "          13       0.16      0.28      0.20        36\n",
            "          14       0.23      0.28      0.25        36\n",
            "          15       0.39      0.25      0.31        36\n",
            "          16       0.62      0.46      0.52        35\n",
            "          17       0.05      0.58      0.09        36\n",
            "          18       0.36      0.37      0.37        35\n",
            "          19       0.69      0.32      0.44        34\n",
            "          20       0.15      0.35      0.21        34\n",
            "          21       0.33      0.29      0.31        34\n",
            "          22       0.53      0.36      0.43        28\n",
            "          23       0.29      0.14      0.19        28\n",
            "          24       0.70      0.25      0.37        28\n",
            "          25       0.22      0.07      0.11        28\n",
            "          26       0.13      0.36      0.19        28\n",
            "          27       0.00      0.00      0.00        28\n",
            "          28       0.04      0.18      0.06        28\n",
            "          29       0.21      0.11      0.14        28\n",
            "          30       0.18      0.57      0.27        28\n",
            "          31       0.38      0.11      0.17        28\n",
            "          32       0.06      0.07      0.07        28\n",
            "          33       0.10      0.04      0.05        28\n",
            "          34       0.23      0.32      0.27        28\n",
            "          35       0.05      0.04      0.04        28\n",
            "          36       0.21      0.21      0.21        28\n",
            "          37       0.08      0.18      0.11        28\n",
            "          38       0.39      0.39      0.39        28\n",
            "          39       0.80      0.14      0.24        28\n",
            "          40       0.36      0.14      0.21        28\n",
            "          41       0.06      0.25      0.10        40\n",
            "          42       0.50      0.07      0.13        40\n",
            "          43       0.28      0.18      0.22        28\n",
            "          44       0.35      0.25      0.29        28\n",
            "          45       0.54      0.56      0.55        36\n",
            "          46       0.25      0.06      0.09        36\n",
            "          47       0.20      0.08      0.12        36\n",
            "          48       0.35      0.19      0.25        36\n",
            "          49       0.00      0.00      0.00        36\n",
            "          50       0.19      0.14      0.16        36\n",
            "          51       0.15      0.22      0.18        36\n",
            "          52       0.11      0.03      0.04        36\n",
            "          53       0.50      0.03      0.05        36\n",
            "          54       0.28      0.14      0.19        36\n",
            "          55       0.08      0.22      0.11        36\n",
            "          56       0.00      0.00      0.00        36\n",
            "          57       0.00      0.00      0.00        36\n",
            "          58       0.37      0.19      0.25        36\n",
            "          59       1.00      0.03      0.05        36\n",
            "          60       0.52      0.31      0.39        36\n",
            "          61       0.33      0.19      0.25        36\n",
            "          62       0.13      0.25      0.17        36\n",
            "          63       0.30      0.50      0.37        36\n",
            "          64       0.29      0.29      0.29        34\n",
            "          65       0.00      0.00      0.00        35\n",
            "          66       0.25      0.03      0.05        34\n",
            "          67       0.65      0.32      0.43        34\n",
            "          68       0.65      0.73      0.69        30\n",
            "          69       0.47      0.32      0.38        28\n",
            "          70       0.38      0.18      0.24        28\n",
            "          71       0.67      0.21      0.32        28\n",
            "          72       0.37      0.25      0.30        28\n",
            "          73       0.31      0.46      0.37        28\n",
            "          74       0.26      0.18      0.21        28\n",
            "          75       0.29      0.07      0.11        28\n",
            "          76       0.15      0.14      0.15        28\n",
            "          77       0.20      0.07      0.11        28\n",
            "          78       0.08      0.14      0.11        28\n",
            "          79       0.60      0.44      0.51        27\n",
            "          80       0.14      0.18      0.16        28\n",
            "          81       0.33      0.03      0.05        40\n",
            "          82       0.44      0.13      0.21        30\n",
            "          83       0.21      0.06      0.09        51\n",
            "          84       0.50      0.06      0.10        53\n",
            "          85       0.78      0.60      0.67        52\n",
            "          86       0.38      0.48      0.42        52\n",
            "          87       0.67      0.67      0.67        36\n",
            "          88       0.31      0.24      0.27        34\n",
            "\n",
            "    accuracy                           0.22      2984\n",
            "   macro avg       0.30      0.22      0.22      2984\n",
            "weighted avg       0.31      0.22      0.22      2984\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.07      0.12        30\n",
            "           1       0.00      0.00      0.00        30\n",
            "           2       0.00      0.00      0.00        30\n",
            "           3       0.00      0.00      0.00        30\n",
            "           4       0.00      0.00      0.00        30\n",
            "           5       0.19      0.20      0.20        30\n",
            "           6       1.00      0.07      0.12        30\n",
            "           7       0.00      0.00      0.00        30\n",
            "           8       0.00      0.00      0.00        30\n",
            "           9       0.00      0.00      0.00        30\n",
            "          10       0.00      0.00      0.00        30\n",
            "          11       0.00      0.00      0.00        30\n",
            "          12       0.00      0.00      0.00        30\n",
            "          13       0.43      0.10      0.16        30\n",
            "          14       0.00      0.00      0.00        30\n",
            "          15       0.00      0.00      0.00        30\n",
            "          16       0.90      0.30      0.45        30\n",
            "          17       0.08      0.20      0.12        30\n",
            "          18       0.64      0.30      0.41        30\n",
            "          19       1.00      0.27      0.42        30\n",
            "          20       0.12      0.30      0.17        30\n",
            "          21       0.62      0.17      0.26        30\n",
            "          22       0.00      0.00      0.00        30\n",
            "          23       0.00      0.00      0.00        30\n",
            "          24       0.00      0.00      0.00        30\n",
            "          25       0.00      0.00      0.00        30\n",
            "          26       0.00      0.00      0.00        30\n",
            "          27       0.00      0.00      0.00        30\n",
            "          28       0.03      0.23      0.05        30\n",
            "          29       0.00      0.00      0.00        30\n",
            "          30       0.00      0.00      0.00        30\n",
            "          31       0.00      0.00      0.00        30\n",
            "          32       0.00      0.00      0.00        30\n",
            "          33       0.00      0.00      0.00        30\n",
            "          34       0.00      0.00      0.00        30\n",
            "          35       0.00      0.00      0.00        40\n",
            "          36       0.12      0.07      0.09        30\n",
            "          37       0.09      0.17      0.12        30\n",
            "          38       0.00      0.00      0.00        30\n",
            "          39       0.00      0.00      0.00        30\n",
            "          40       0.00      0.00      0.00        30\n",
            "          41       0.01      0.02      0.02        60\n",
            "          42       0.00      0.00      0.00        50\n",
            "          43       0.01      0.33      0.01        30\n",
            "          44       0.00      0.00      0.00        29\n",
            "          45       0.54      0.23      0.33        30\n",
            "          46       0.00      0.00      0.00        30\n",
            "          47       0.00      0.00      0.00        30\n",
            "          48       0.00      0.00      0.00        30\n",
            "          49       0.00      0.00      0.00        30\n",
            "          50       0.00      0.00      0.00        30\n",
            "          51       0.00      0.00      0.00        30\n",
            "          52       0.00      0.00      0.00        30\n",
            "          53       0.00      0.00      0.00        30\n",
            "          54       0.00      0.00      0.00        30\n",
            "          55       0.00      0.00      0.00        30\n",
            "          56       0.00      0.00      0.00        30\n",
            "          57       0.50      0.03      0.06        30\n",
            "          58       1.00      0.23      0.38        30\n",
            "          59       0.00      0.00      0.00        30\n",
            "          60       0.86      0.20      0.32        30\n",
            "          61       0.00      0.00      0.00        30\n",
            "          62       0.00      0.00      0.00        30\n",
            "          63       0.86      0.20      0.32        30\n",
            "          64       0.47      0.27      0.34        30\n",
            "          65       0.17      0.07      0.10        30\n",
            "          66       0.62      0.17      0.26        30\n",
            "          67       0.50      0.10      0.17        30\n",
            "          68       0.00      0.00      0.00        30\n",
            "          69       0.00      0.00      0.00        30\n",
            "          70       0.00      0.00      0.00        30\n",
            "          71       0.00      0.00      0.00        30\n",
            "          72       0.00      0.00      0.00        30\n",
            "          73       0.00      0.00      0.00        30\n",
            "          74       0.00      0.00      0.00        30\n",
            "          75       0.00      0.00      0.00        30\n",
            "          76       0.00      0.00      0.00        30\n",
            "          77       0.00      0.00      0.00        30\n",
            "          78       0.00      0.00      0.00        30\n",
            "          79       0.00      0.00      0.00        30\n",
            "          80       0.03      0.03      0.03        30\n",
            "          81       0.00      0.00      0.00        60\n",
            "          82       0.00      0.00      0.00        39\n",
            "          83       0.00      0.00      0.00        30\n",
            "          84       0.00      0.00      0.00        30\n",
            "          85       0.00      0.00      0.00        30\n",
            "          86       0.00      0.00      0.00        30\n",
            "          87       0.00      0.00      0.00        20\n",
            "          88       0.17      0.13      0.15        30\n",
            "\n",
            "    accuracy                           0.05      2758\n",
            "   macro avg       0.13      0.05      0.06      2758\n",
            "weighted avg       0.12      0.05      0.06      2758\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBlCM33ptadd"
      },
      "source": [
        "#MLP Classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8TAcVj5tZWd"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJSJKGuxttqN",
        "outputId": "4bcb5ba3-9622-4244-95e4-85d301aba429"
      },
      "source": [
        "MLP1 = MLPClassifier(hidden_layer_sizes=(1000), max_iter=500)\n",
        "MLP1.fit(x_train, y_train)\n",
        "print(accuracy_score(y_val, MLP1.predict(x_val)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5164209115281502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjUm64yOuGSb",
        "outputId": "043ac9c7-6a47-4efc-fe3a-b282d8ce5b32"
      },
      "source": [
        "print(accuracy_score(y_test, MLP1.predict(x_test)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.16134880348078318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8X3hLTp0kV8",
        "outputId": "8cbb5bc6-270e-4d0b-e79a-f32816e69b42"
      },
      "source": [
        "MLP2 = MLPClassifier(hidden_layer_sizes=(1000, 1000, 5000), max_iter=500)\n",
        "MLP2.fit(x_train, y_train)\n",
        "print(accuracy_score(y_val, MLP2.predict(x_val)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6437667560321716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWNzVj2rLEBp",
        "outputId": "029e4281-6fde-4aa3-f0ea-54da82cdebf8"
      },
      "source": [
        "print(accuracy_score(y_test, MLP2.predict(x_test)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22008701957940538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLzc3y0OMJQl",
        "outputId": "c0fd23ab-2ae8-49aa-8732-12bb085b4ff1"
      },
      "source": [
        "print(classification_report(y_test, MLP2.predict(x_test)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.20      0.32        30\n",
            "           1       0.69      0.30      0.42        30\n",
            "           2       0.55      0.20      0.29        30\n",
            "           3       0.00      0.00      0.00        30\n",
            "           4       1.00      0.10      0.18        30\n",
            "           5       0.53      0.30      0.38        30\n",
            "           6       0.75      0.30      0.43        30\n",
            "           7       1.00      0.23      0.38        30\n",
            "           8       0.47      0.30      0.37        30\n",
            "           9       0.71      0.17      0.27        30\n",
            "          10       0.27      0.30      0.29        30\n",
            "          11       0.32      0.20      0.24        30\n",
            "          12       0.58      0.23      0.33        30\n",
            "          13       0.28      0.30      0.29        30\n",
            "          14       0.33      0.20      0.25        30\n",
            "          15       0.33      0.40      0.36        30\n",
            "          16       0.83      0.33      0.48        30\n",
            "          17       0.26      0.53      0.35        30\n",
            "          18       0.90      0.30      0.45        30\n",
            "          19       0.19      0.33      0.24        30\n",
            "          20       0.47      0.30      0.37        30\n",
            "          21       0.75      0.30      0.43        30\n",
            "          22       0.00      0.00      0.00        30\n",
            "          23       1.00      0.20      0.33        30\n",
            "          24       0.00      0.00      0.00        30\n",
            "          25       0.00      0.00      0.00        30\n",
            "          26       1.00      0.03      0.06        30\n",
            "          27       0.00      0.00      0.00        30\n",
            "          28       0.00      0.00      0.00        30\n",
            "          29       0.00      0.00      0.00        30\n",
            "          30       0.00      0.00      0.00        30\n",
            "          31       0.00      0.00      0.00        30\n",
            "          32       0.17      0.17      0.17        30\n",
            "          33       0.25      0.13      0.17        30\n",
            "          34       0.00      0.00      0.00        30\n",
            "          35       0.13      0.93      0.22        40\n",
            "          36       0.09      0.30      0.14        30\n",
            "          37       0.05      0.73      0.10        30\n",
            "          38       0.33      0.07      0.11        30\n",
            "          39       0.06      0.07      0.07        30\n",
            "          40       0.20      0.03      0.06        30\n",
            "          41       0.41      0.28      0.34        60\n",
            "          42       0.59      0.46      0.52        50\n",
            "          43       1.00      0.13      0.24        30\n",
            "          44       0.50      0.24      0.33        29\n",
            "          45       0.40      0.27      0.32        30\n",
            "          46       0.67      0.27      0.38        30\n",
            "          47       0.86      0.20      0.32        30\n",
            "          48       1.00      0.23      0.38        30\n",
            "          49       0.33      0.30      0.32        30\n",
            "          50       0.40      0.27      0.32        30\n",
            "          51       0.35      0.30      0.32        30\n",
            "          52       0.07      0.40      0.12        30\n",
            "          53       0.12      0.10      0.11        30\n",
            "          54       0.10      0.67      0.18        30\n",
            "          55       0.20      0.37      0.26        30\n",
            "          56       0.60      0.10      0.17        30\n",
            "          57       0.24      0.30      0.26        30\n",
            "          58       0.90      0.30      0.45        30\n",
            "          59       0.50      0.30      0.37        30\n",
            "          60       0.71      0.33      0.45        30\n",
            "          61       0.21      0.43      0.29        30\n",
            "          62       0.12      0.37      0.18        30\n",
            "          63       0.77      0.33      0.47        30\n",
            "          64       1.00      0.33      0.50        30\n",
            "          65       0.32      0.33      0.33        30\n",
            "          66       0.21      0.33      0.26        30\n",
            "          67       0.75      0.30      0.43        30\n",
            "          68       0.00      0.00      0.00        30\n",
            "          69       0.00      0.00      0.00        30\n",
            "          70       0.00      0.00      0.00        30\n",
            "          71       0.00      0.00      0.00        30\n",
            "          72       0.00      0.00      0.00        30\n",
            "          73       0.00      0.00      0.00        30\n",
            "          74       0.00      0.00      0.00        30\n",
            "          75       0.00      0.00      0.00        30\n",
            "          76       0.00      0.00      0.00        30\n",
            "          77       0.22      0.20      0.21        30\n",
            "          78       0.05      0.07      0.06        30\n",
            "          79       0.00      0.00      0.00        30\n",
            "          80       0.12      0.57      0.20        30\n",
            "          81       0.18      0.27      0.21        60\n",
            "          82       0.05      0.03      0.03        39\n",
            "          83       1.00      0.07      0.12        30\n",
            "          84       0.47      0.23      0.31        30\n",
            "          85       1.00      0.07      0.12        30\n",
            "          86       0.50      0.40      0.44        30\n",
            "          87       0.67      0.20      0.31        20\n",
            "          88       0.90      0.30      0.45        30\n",
            "\n",
            "    accuracy                           0.22      2758\n",
            "   macro avg       0.38      0.22      0.22      2758\n",
            "weighted avg       0.38      0.22      0.22      2758\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}