{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SarcasmV2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrPVcMItXdx35gLLorqImo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhnhan311201/CS114.L11.KHCL/blob/master/SarcasmV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "082Vgc1nOPmI"
      },
      "source": [
        "# Code : Lê Quang Huy\n",
        "# Nội dung : \n",
        "\n",
        "- Nhận dạng văn bản trào phúng dựa vào tiêu đề.\n",
        "\n",
        "# Ý tưởng : \n",
        "- Dùng Model Naive Bayes để  nhận dạng.\n",
        "\n",
        "# Các bước tiến hành:\n",
        "- Lấy data từ https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection.\n",
        "- Đọc dữ liệu từ file json thứ nhất, chia làm 2 bộ ngẫu nhiên để train và test (Đảm bảo Dữ liệu train > Dữ liệu test)\n",
        "- Lọc bỏ StopWord và các dấu chấm câu.\n",
        "- Thực hiện train tương tự nội dung học trong Lớp toán cho KHMT.\n",
        "- Đọc file dữ liệu thứ 2 kiểm tra accurracy.\n",
        "\n",
        "# Kết quả thực hiện :\n",
        "- Train được model .\n",
        "- Accurracy 85%\n",
        "- Chưa làm được Confussed Matrix \n",
        "- Chưa tính được recall và precision ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XQu5qgbtBQ3"
      },
      "source": [
        "!git clone https://github.com/thanhnhan311201/CS114.L11.KHCL.git\n",
        "!pip install stop-words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2_3HNgltSsJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import json\n",
        "import string"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPRLF9pZtW35",
        "outputId": "a2c60119-488e-465f-fbf0-0a498340f547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "file_ = pd.read_json(\"/content/CS114.L11.KHCL/LogisticsRegression/ThucHanh/Sarcasm_Project/Sarcasm_Headlines_Dataset.json\",lines=True)\n",
        "del file_['article_link'] # xóa cột article_link.\n",
        "\n",
        "# chia data thành 2 phần random để  train và test; X_test, Y_test chiếm 1/3 dữ liệu.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(file_['headline'], file_['is_sarcastic'], test_size = 0.33, random_state = 50)\n",
        "file_.head() # in file_"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0\n",
              "2  mom starting to fear son's web series closest ...             1\n",
              "3  boehner just wants wife to listen, not come up...             1\n",
              "4  j.k. rowling wishes snape happy birthday in th...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xih1zPIut-WU",
        "outputId": "2d185c59-5c7b-4c52-9e8c-8102853efa50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "List_StopWord = set(stopwords.words('english')) # Danh Sach những từ sẽ xuất hiện nhiều trong câu nhưng không đóng góp quá nhiều ý nghĩa.\n",
        "List_Punctuation = list(string.punctuation) # Danh sách dấu chấm câu"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlMe25p3uYI8"
      },
      "source": [
        "def Normalize(text): # Xóa hết dấu câu cùng với stopword ra khỏi các tiêu đề.\n",
        "  for x in List_StopWord:\n",
        "    text.replace(x, '')\n",
        "  for x in List_Punctuation:\n",
        "    text.replace(x, '')\n",
        "      \n",
        "Normalize(X_train)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8uFhHZ2uj-l"
      },
      "source": [
        "#Tạo Model Naive Bayes \n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from collections import Counter\n",
        "\n",
        "class NaiveBayes(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self):\n",
        "      pass\n",
        "  \n",
        "  def CreateListWord(self, ListHeadLine):\n",
        "    all_words = [] \n",
        "    for headline in ListHeadLine : # đọc tất cả các từ trong ListHeadLine và đưa vào all_words\n",
        "      all_words.extend(headline.split()) \n",
        "    return Counter(all_words) # Trả về danh sách 1 từ đươc cuất hiện bao nhiêu lần.\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    total_count = X.count() # đếm xem X có bao nhiêu dòng header -> Kích thước bộ test.\n",
        "    class_counts = y.value_counts() # đếm xem có bao nhiêu kết quả cần phân loại, ở đây là 2 loại : Sarcasm :1 và Notsarcasm :0\n",
        "    self.class_probs = class_counts/total_count \n",
        "    #class_probs[0] = P(NotSarcasm) \n",
        "    #class_probs[1] = P(Sarcasm)\n",
        "\n",
        "    #chia X ra làm 2 phần \n",
        "    X_Sarcasm = X[y==1] #những headline được đánh nhãn Sarcasm \n",
        "    X_NotSarc = X[y==0] #những headline không được đánh nhãn Sarcasm \n",
        "\n",
        "    \"\"\"Tạo 2 danh sách CountWordSarcasm và CountWordNotSar cho ta biết số lần xuất hiện của 1 từ trong X ở mỗi nhãn Sarcasm và NotSarcasm\"\"\"\n",
        "    CountWordSarcasm = dict(self.CreateListWord(X_Sarcasm)) #Danh sách lưu số lần xuất hiện của 1 từ trong phần headline được đánh nhãn Sarcasm.\n",
        "    CountWordNotSar  = dict(self.CreateListWord(X_NotSarc))\n",
        "\n",
        "    CountWordSarcasm.update({k:0 for k in CountWordNotSar if k not in CountWordSarcasm})\n",
        "    CountWordNotSar.update({k:0 for k in CountWordSarcasm if k not in CountWordNotSar})\n",
        "\n",
        "    \"\"\"Tính P(Xi|S) và P(Xi|NS) sau khi smoothing các giá trị\"\"\"\n",
        "    CountWordSarcasm  = pd.Series(CountWordSarcasm)\n",
        "    CountWordNotSar = pd.Series(CountWordNotSar)\n",
        "\n",
        "    self.P_Xi_S = (CountWordSarcasm+1)/(CountWordSarcasm.sum() + 1)\n",
        "    self.P_Xi_NS = (CountWordNotSar+1)/(CountWordNotSar.sum() + 1)\n",
        "    return self\n",
        "  \n",
        "  def predict(self, X):\n",
        "    y_pred = []\n",
        "    for x in X:\n",
        "      #Tính P(x|S)\n",
        "      x_counts = pd.Series(self.CreateListWord([x])) #đếm những từ có trong X\n",
        "      P_xi_S = self.P_Xi_S.reindex(x_counts.index) ** x_counts #Tính P(xi|S) với xi là từ xuất hiện trong X\n",
        "      P_xi_S.dropna(inplace=True) #Những từ nào không xuất hiện thì bỏ qua những từ đó\n",
        "      P_x_S = self.class_probs[1]*P_xi_S.product() #P(X|S) ~ Tích P(xi|S)* P(S)\n",
        "\n",
        "      #Tính P(x|NS)\n",
        "      P_xi_NS = self.P_Xi_NS.reindex(x_counts.index) ** x_counts\n",
        "      P_xi_NS.dropna(inplace=True)\n",
        "      P_x_NS = self.class_probs[0]*P_xi_NS.product()\n",
        "\n",
        "      #So sánh 2 tỉ lệ P(X|S) và P(X|NS), P(X|S) lớn hơn thì dự đoán rằng đó là Sarcasm. \n",
        "      y = P_x_S >= P_x_NS \n",
        "      y_pred.append(y)\n",
        "    return pd.Series(y_pred, index=X.index)\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUM2VcxbGaiL",
        "outputId": "a8b57d5a-b010-40a3-abf7-ec246db19cb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nb_model = NaiveBayes()\n",
        "nb_model.fit(X_train, Y_train)\n",
        "\n",
        "Normalize(X_test)\n",
        "nb_model.score(X_test, Y_test)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8593147265713638"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVLIz_vaNHqf",
        "outputId": "29476636-ac1d-407b-d08e-543b7b0ecd79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file1 = pd.read_json(\"/content/CS114.L11.KHCL/LogisticsRegression/ThucHanh/Sarcasm_Project/Sarcasm_Headlines_Dataset_v2.json\", lines = True)\n",
        "del file1['article_link']\n",
        "X_test = file1['headline']\n",
        "Y_test = file1['is_sarcastic']\n",
        "nb_model.score(X_test, Y_test)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9161046856983123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    }
  ]
}